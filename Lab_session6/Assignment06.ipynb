{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the inputs and outputs for the AND gate\n",
    "inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "outputs = [0, 0, 0, 1]\n",
    "\n",
    "# Define the initial weights and learning rate\n",
    "W0 = 10\n",
    "W1 = 0.2\n",
    "W2 = -0.75\n",
    "alpha = 0.05\n",
    "\n",
    "# Define the activation functions\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bipolar_step(x):\n",
    "  if x < 0:\n",
    "    return -1\n",
    "  else:\n",
    "    return 1\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "  if x < 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the perceptron function\n",
    "def perceptron(A, B, activation):\n",
    "  # Compute the weighted sum\n",
    "  weighted_sum = W0 + W1 * A + W2 * B\n",
    "  # Apply the activation function\n",
    "  output = activation(weighted_sum)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(activation):\n",
    "  total_error = 0\n",
    "  for i in range(len(inputs)):\n",
    "    # Get the input and output pair\n",
    "    A, B = inputs[i]\n",
    "    T = outputs[i]\n",
    "    # Get the perceptron output\n",
    "    Z = perceptron(A, B, activation)\n",
    "    # Calculate the squared error\n",
    "    squared_error = (T - Z) ** 2\n",
    "    # Add to the total error\n",
    "    total_error += squared_error\n",
    "  return total_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train the perceptron with a given activation function\n",
    "def train(activation):\n",
    "  # Define global variables for the weights\n",
    "  global W0, W1, W2\n",
    "  # Define a list to store the errors for each epoch\n",
    "  errors = []\n",
    "  # Define a variable to track the number of epochs\n",
    "  epochs = 0\n",
    "  # Train the perceptron until the error is zero\n",
    "  while error(activation) > 0:\n",
    "    # Increment the number of epochs\n",
    "    epochs += 1\n",
    "    # Store the current error\n",
    "    errors.append(error(activation))\n",
    "    # Loop through the input and output pairs\n",
    "    for i in range(len(inputs)):\n",
    "      # Get the input and output pair\n",
    "      A, B = inputs[i]\n",
    "      T = outputs[i]\n",
    "      # Get the perceptron output\n",
    "      Z = perceptron(A, B, activation)\n",
    "      # Update the weights\n",
    "      if activation == bipolar_step:\n",
    "        W0 = W0 + alpha * (T - Z) * 1\n",
    "        W1 = W1 + alpha * (T - Z) * A\n",
    "        W2 = W2 + alpha * (T - Z) * B\n",
    "      elif activation == sigmoid:\n",
    "        W0 = W0 + alpha * (T - Z) * Z * (1 - Z) * 1\n",
    "        W1 = W1 + alpha * (T - Z) * Z * (1 - Z) * A\n",
    "        W2 = W2 + alpha * (T - Z) * Z * (1 - Z) * B\n",
    "      elif activation == relu:\n",
    "        W0 = W0 + alpha * (T - Z) * 1\n",
    "        W1 = W1 + alpha * (T - Z) * A\n",
    "        W2 = W2 + alpha * (T - Z) * B\n",
    "  # Return the final weights, number of epochs, and errors\n",
    "  return W0, W1, W2, epochs, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a list of activation functions\n",
    "activations = [bipolar_step, sigmoid, relu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the activation functions\n",
    "for activation in activations:\n",
    "  # Reset the weights to the initial values\n",
    "  W0 = 10\n",
    "  W1 = 0.2\n",
    "  W2 = -0.75\n",
    "  # Train the perceptron with the activation function\n",
    "  W0, W1, W2, epochs, errors = train(activation)\n",
    "  # Print the results\n",
    "  print(\"Activation function:\", activation.__name__)\n",
    "  print(\"Final weights:\")\n",
    "  print(\"W0 =\", W0)\n",
    "  print(\"W1 =\", W1)\n",
    "  print(\"W2 =\", W2)\n",
    "  print(\"Number of epochs:\", epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Plot the errors against the epochs\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, epochs + 1), errors)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Perceptron Learning Curve with \" + activation.__name__)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of learning rates\n",
    "learning_rates = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "# Define a list to store the number of epochs for each learning rate\n",
    "epochs_list = []\n",
    "\n",
    "# Loop through the learning rates\n",
    "for alpha in learning_rates:\n",
    "  # Reset the weights to the initial values\n",
    "  W0 = 10\n",
    "  W1 = 0.2\n",
    "  W2 = -0.75\n",
    "  # Train the perceptron with the learning rate\n",
    "  epochs = train(alpha)\n",
    "  # Store the number of epochs\n",
    "  epochs_list.append(epochs)\n",
    "  # Print the results\n",
    "  print(\"Learning rate:\", alpha)\n",
    "  print(\"Number of epochs:\", epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(learning_rates, epochs_list)\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Number of epochs\")\n",
    "plt.title(\"Perceptron Learning Rate vs Epochs\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
